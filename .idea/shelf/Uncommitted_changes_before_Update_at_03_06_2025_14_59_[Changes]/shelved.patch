Index: app/main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from fastapi.middleware.cors import CORSMiddleware\r\nfrom fastapi import FastAPI\r\n\r\nfrom app.get_traffic_volume_endpoint import get_traffic_volume\r\nfrom app.startup.load_models import load_traffic_model\r\n\r\napp = FastAPI()\r\n\r\norigins = [\r\n    \"*\"\r\n]\r\n\r\napp.add_middleware(\r\n    CORSMiddleware,\r\n    allow_origins=origins,\r\n    allow_credentials=True,\r\n    allow_methods=[\"*\"],\r\n    allow_headers=[\"*\"]\r\n)\r\n\r\n\r\napp.traffic_model = load_traffic_model()\r\n\r\napp.include_router(get_traffic_volume.router)\r\n
===================================================================
diff --git a/app/main.py b/app/main.py
--- a/app/main.py	
+++ b/app/main.py	
@@ -1,10 +1,13 @@
 from fastapi.middleware.cors import CORSMiddleware
 from fastapi import FastAPI
 
-from app.get_traffic_volume_endpoint import get_traffic_volume
-from app.startup.load_models import load_traffic_model
+from app.get_traffic_volume_endpoint.get_traffic_volume import router as traffic_router
+
+# from app.get_traffic_volume_endpoint import get_traffic_volume
+# from app.startup.load_models import load_traffic_model
 
-app = FastAPI()
+
+app = FastAPI(title="Traffic Prediction")
 
 origins = [
     "*"
@@ -18,7 +21,4 @@
     allow_headers=["*"]
 )
 
-
-app.traffic_model = load_traffic_model()
-
-app.include_router(get_traffic_volume.router)
+app.include_router(traffic_router)
Index: app/get_traffic_volume_endpoint/get_traffic_volume.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from fastapi import APIRouter, Request\r\n\r\nfrom .shemas import TrafficRequest, TrafficResponse\r\n\r\nimport pandas as pd\r\n\r\nrouter = APIRouter(\r\n    prefix=\"/traffic\"\r\n)\r\n\r\n\r\n@router.post(\"/volume\")\r\nasync def get_traffic_prediction(request: Request, traffic_request: TrafficRequest):\r\n\r\n    traffic_model = request.app.state.traffic_model\r\n\r\n    feature_space = {\r\n        'rain_1h': [traffic_request.rain],\r\n        'snow_1h': [traffic_request.snow],\r\n        'temp': [traffic_request.temp],\r\n        'clouds_all': [traffic_request.cloud],\r\n        'hour': [traffic_request.hour],\r\n        'day': [traffic_request.day],\r\n        'month': [traffic_request.month]\r\n    }\r\n\r\n    transformed_feature_space = pd.DataFrame.from_dict(feature_space)\r\n\r\n    traffic_volume = traffic_model.predict(transformed_feature_space)\r\n\r\n    return TrafficResponse(traffic_volume=traffic_volume)\r\n
===================================================================
diff --git a/app/get_traffic_volume_endpoint/get_traffic_volume.py b/app/get_traffic_volume_endpoint/get_traffic_volume.py
--- a/app/get_traffic_volume_endpoint/get_traffic_volume.py	
+++ b/app/get_traffic_volume_endpoint/get_traffic_volume.py	
@@ -1,31 +1,82 @@
-from fastapi import APIRouter, Request
+from fastapi import APIRouter, HTTPException
+from datetime import datetime
+
+from .schemas import RouteRequest, PredictionResponse
+from scipy.spatial import KDTree
+from app.utils.geo import to_mercator
+import numpy as np
+
+from app.startup.load_models import tree, link_gps_df, load_all
+from app.utils.geo import get_nearest_links, extrapolate_speed
+from app.utils.congestion import classify_congestion
+from app.utils.gnn_inference import predict_speed
+from app.utils.geo import build_link_neighbors
+from pyproj import Transformer
+
+transformer = Transformer.from_crs("epsg:4326", "epsg:3857", always_xy=True)
+model, x_map, edge_index, link_ids = load_all()
+neighbors_dict = build_link_neighbors(edge_index, link_ids)
+
 
-from .shemas import TrafficRequest, TrafficResponse
+router = APIRouter()
 
-import pandas as pd
 
-router = APIRouter(
-    prefix="/traffic"
-)
+@router.post("/predict_traffic", response_model=PredictionResponse)
+async def predict_traffic(req: RouteRequest):
+    # 1. получаем ближайшие link_id по координатам маршрута
+    coords = [tuple(pt) for pt in req.coords]
+    nearest_links = get_nearest_links(coords, tree, link_gps_df)
+    if not nearest_links:
+        raise HTTPException(400, "Маршрут не пересекает известных сегментов (link_id)")
 
+    # 2. получаем временные признаки (дальше)
+    dt = datetime.fromisoformat(req.datetime)
 
-@router.post("/volume")
-async def get_traffic_prediction(request: Request, traffic_request: TrafficRequest):
+    # 3. выполняем предсказание скорости по всей сети (GNN-инференс)
+    pred_dict = predict_speed(model, x_map, edge_index, dt)
 
-    traffic_model = request.app.state.traffic_model
+    # 4. построим KDTree по центроидам link_id, по которым есть предсказания
+    gps_coords = link_gps_df[link_gps_df["link_id"].isin(pred_dict.keys())]
+    lid_to_coord = gps_coords.groupby("link_id")[["lat", "lon"]].mean().reset_index()
+    coord_array = lid_to_coord[["lon", "lat"]].values
+    lid_list = lid_to_coord["link_id"].tolist()
 
-    feature_space = {
-        'rain_1h': [traffic_request.rain],
-        'snow_1h': [traffic_request.snow],
-        'temp': [traffic_request.temp],
-        'clouds_all': [traffic_request.cloud],
-        'hour': [traffic_request.hour],
-        'day': [traffic_request.day],
-        'month': [traffic_request.month]
-    }
+    lons, lats = coord_array[:, 0], coord_array[:, 1]
+    mx, my = transformer.transform(lons.tolist(), lats.tolist())
+    lid_coords_merc = list(zip(mx, my))
 
-    transformed_feature_space = pd.DataFrame.from_dict(feature_space)
+    lid_tree = KDTree(lid_coords_merc)
 
-    traffic_volume = traffic_model.predict(transformed_feature_space)
+    # обрабатываем каждую координату маршрута
+    # деалем обратную операцию операции 1. т.е. теперь строим дерево по link_id и ищем для них ближайшие точки
+    route = []
+    for lon, lat in req.coords:
+        mx, my = to_mercator(lon, lat)
+        dist, idx = lid_tree.query((mx, my), distance_upper_bound=100)
 
-    return TrafficResponse(traffic_volume=traffic_volume)
+        if np.isinf(dist) or idx >= len(lid_list):
+            avg_speed = float(np.mean(list(pred_dict.values()))) if pred_dict else None
+            level, color = classify_congestion(avg_speed)
+            route.append({
+                "coord": [lon, lat],
+                "speed": avg_speed,
+                "color": color,
+                "approx": True
+            })
+            continue
+        lid = lid_list[idx]
+        if lid in pred_dict:
+            speed = pred_dict[lid]
+            approx = False
+        else:
+            speed, approx = extrapolate_speed(lid, pred_dict, neighbors_dict)
+        level, color = classify_congestion(speed)
+        route.append({
+            "coord": [lon, lat],
+            "speed": float(speed),
+            "color": color,
+            "approx": approx
+        })
+    return {"route": route}
+
+
Index: run_application.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from app.main import app\r\nimport uvicorn\r\n\r\nif __name__ == \"__main__\":\r\n    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\r\n
===================================================================
diff --git a/run_application.py b/run_application.py
--- a/run_application.py	
+++ b/run_application.py	
@@ -2,4 +2,4 @@
 import uvicorn
 
 if __name__ == "__main__":
-    uvicorn.run(app, host="0.0.0.0", port=5000)
+    uvicorn.run("app.main:app", host="127.0.0.1", port=8000, reload=True)
Index: app/startup/load_models.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># from sklearn.ensemble import RandomForestRegressor\r\nimport pickle\r\n\r\nRandomForestRegressor = 0\r\n\r\n\r\ndef load_traffic_model() -> RandomForestRegressor:\r\n\r\n    # file = open(\"./app/models/traffic_model.pkl\", \"rb\")\r\n    # if not res:\r\n    #     random_forest_regressor = 0\r\n    # else:\r\n    #     random_forest_regressor = pickle.load(file)\r\n    #     file.close()\r\n\r\n    # return random_forest_regressor\r\n    return 0
===================================================================
diff --git a/app/startup/load_models.py b/app/startup/load_models.py
--- a/app/startup/load_models.py	
+++ b/app/startup/load_models.py	
@@ -1,17 +1,43 @@
-# from sklearn.ensemble import RandomForestRegressor
 import pickle
+import pandas as pd
+from scipy.spatial import KDTree
+from pyproj import Transformer
+import torch
+from app.models.model import TrafficGNN
+
+
+link_gps_df = pd.read_csv("data/link_gps.csv", sep='\t',
+                          header=None, names=["link_id", "lon", "lat"])
+transformer = Transformer.from_crs("epsg:4326", "epsg:3857",
+                                   always_xy=True)
+link_gps_df[["mercator_x", "mercator_y"]] = link_gps_df.apply(
+    lambda row: pd.Series(transformer.transform(row["lon"], row["lat"])), axis=1)
+coords = list(zip(link_gps_df["mercator_x"], link_gps_df["mercator_y"]))
+tree = KDTree(coords)
+
 
-RandomForestRegressor = 0
+def get_traffic_model(model_path: str = "app/models/traffic_gnn_model.pt",
+                      in_channels: int = 21,
+                      hidden_channels: int = 64):
+    model = TrafficGNN(in_channels=in_channels, hidden_channels=hidden_channels)
+    model.load_state_dict(torch.load(model_path, map_location='cpu'))
+    model.eval()
+    return model
 
 
-def load_traffic_model() -> RandomForestRegressor:
+def load_pickle(path: str):
+    with open(path, 'rb') as f:
+        return pickle.load(f)
 
-    # file = open("./app/models/traffic_model.pkl", "rb")
-    # if not res:
-    #     random_forest_regressor = 0
-    # else:
-    #     random_forest_regressor = pickle.load(file)
-    #     file.close()
 
-    # return random_forest_regressor
-    return 0
\ No newline at end of file
+def load_all(model_path='app/models/traffic_gnn_model.pt',
+             xmap_path='app/models/x_map.pkl',
+             lid_path='app/models/link_ids.pkl',
+             in_channels=21,
+             hidden_channels=64):
+    model = get_traffic_model(model_path, in_channels, hidden_channels)
+    x_map = load_pickle(xmap_path)
+    edge_index = torch.load("app/models/edge_index.pt", map_location='cpu')
+    link_ids = load_pickle(lid_path)
+    return model, x_map, edge_index, link_ids
+
